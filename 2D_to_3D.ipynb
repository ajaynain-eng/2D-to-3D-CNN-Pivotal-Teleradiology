{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "2D_to_3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaynain-eng/2D-to-3D-CNN-Pivotal-Teleradiology/blob/main/2D_to_3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVmxAFAHfA6V"
      },
      "source": [
        " import os\n",
        " os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JilmO9jCiUef",
        "outputId": "4933f81b-d0ba-4b20-c060-274d811f04fe"
      },
      "source": [
        "!kaggle datasets download -d ymirsky/medical-deepfakes-lung-cancer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading medical-deepfakes-lung-cancer.zip to /content\n",
            "100% 5.99G/5.99G [02:10<00:00, 57.1MB/s]\n",
            "100% 5.99G/5.99G [02:10<00:00, 49.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J1vyJRdnc4j",
        "outputId": "dd72bdfc-0337-4cce-c2ae-c3d2c8a29d57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xzkoHiWiXR4"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzyttgmsjjmX",
        "outputId": "ef0ce064-6e10-4c35-c827-edd4be814ea4"
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS24mY6xDXGi",
        "outputId": "2428058a-b6c3-41b8-b8d6-ff91936444b8"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKcATmeGjnlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e6a9f6-d942-480c-e6fa-1be8ff11be6e"
      },
      "source": [
        "# importing supporting libraries\n",
        "import pandas as pd                    # to create and read data frame and series\n",
        "import numpy as np                     # to work with array\n",
        "from matplotlib import pyplot as plt   # to plot figures\n",
        "import seaborn as sns                  # to plot interactive metric plot and heatmaps\n",
        "import cv2                             # to read and show image\n",
        "from skimage.transform import resize   # as we need to resize the image to reduce model complexity and get optimum accuracy\n",
        "import scipy.linalg as linalg\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import pydicom as dicom\n",
        "import glob\n",
        "import scipy.ndimage\n",
        "from skimage import measure, morphology\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "\n",
        "# importing required CNN algorithms, optimizers and activation function\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "#from keras.applications import VGG16\n",
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv1D, Conv2D, Conv3D, MaxPool3D, ZeroPadding3D, Dropout, BatchNormalization\n",
        "from keras.layers import Flatten, Dense, Input\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model\n",
        "from keras import callbacks\n",
        "from keras.metrics import Precision, Recall, RecallAtPrecision\n",
        "# importing pretrained model VGG16 and VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import random_zoom, random_shear, random_shift, random_rotation\n",
        "import time\n",
        "\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "from matplotlib.projections import Axes3D\n",
        "from plotly.figure_factory import create_trisurf\n",
        "from mpl_toolkits import mplot3d\n",
        "from PIL import Image\n",
        "\n",
        "tfa.metrics.RSquare(name = 'r_square')\n",
        "# tfa.metrics.F1Score(name = 'f1_score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_addons.metrics.r_square.RSquare at 0x7facf5467d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfTPTHreOIuI"
      },
      "source": [
        "Our first step is data cleaning.                                                \n",
        "Lets crop the images to a standard size. A shape of (110,110) for every dicom image seems to be good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16-UvOvjq98"
      },
      "source": [
        "def transform_to_hu(medical_image, image):\n",
        "    intercept = medical_image.RescaleIntercept\n",
        "    slope = medical_image.RescaleSlope\n",
        "    hu_image = image * slope + intercept\n",
        "    return hu_image\n",
        "\n",
        "def window_image(image, window_center, window_width):\n",
        "    img_min = window_center - window_width // 2\n",
        "    img_max = window_center + window_width // 2\n",
        "    window_image = image.copy()\n",
        "    window_image[window_image < img_min] = img_min\n",
        "    window_image[window_image > img_max] = img_max\n",
        "    return window_image\n",
        "\n",
        "def crop_image(image, display=False):\n",
        "# Create a mask with the background pixels\n",
        "    mask = image == 0\n",
        "# Find the lung area\n",
        "    coords = np.array(np.nonzero(~mask))\n",
        "    top_left = np.min(coords, axis=1)\n",
        "    bottom_right = np.max(coords, axis=1)\n",
        "# Remove the background\n",
        "    croped_image = image[top_left[0]:bottom_right[0],\n",
        "                         top_left[1]:bottom_right[1]]\n",
        "    return croped_image\n",
        "\n",
        "def no_crop(medical_img):         # changes the medical image in pixel array and returns the original image\n",
        "    return medical_img.pixel_array\n",
        "\n",
        "def crop_the_image_1(medical_img):     # crop the image corresponding to HU range for lungs\n",
        "    temp_medical_img = medical_img\n",
        "    temp_img = temp_medical_img.pixel_array\n",
        "    hu_image = transform_to_hu(temp_medical_img,temp_img)\n",
        "    lung_image = window_image(hu_image, -500, 1500)       # (-1000, 400)\n",
        "    croped_img = crop_image(lung_image, display=False)\n",
        "    return croped_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6sfOH61jtzH"
      },
      "source": [
        "def get_data(pid, crop_function):         #  corresponding to every patient, it selects 110 slices and crop them to standard size to give 3D and 2D image data\n",
        "    files = glob.glob(\"/content/CT_Scans/EXP1_blind/\"+ pid +\"/*.dcm\")\n",
        "    slices = [dicom.read_file(i) for i in files]\n",
        "    slices = sorted(slices, key=lambda s: s.SliceLocation)\n",
        "    s = 0\n",
        "    views = np.empty([110,110,110])\n",
        "    x = (len(slices)-4)/109      # Select 110 slices\n",
        "    for i in range(110):\n",
        "        t = int(4+(x*i))\n",
        "        try:\n",
        "            t_img = crop_function(slices[t])\n",
        "            t_img = resize(t_img, (110,110))\n",
        "        except:\n",
        "            t_img = crop_function(slices[t-1])\n",
        "            t_img = resize(t_img, (110,110))\n",
        "            s = s + 1\n",
        "        views[:,:,i] = t_img          # 3D image array, CT scanes with shape (110,110,110)\n",
        "        i += 1\n",
        "    img_2d = views[55,:,:].T\n",
        "    img_2d = img_2d[::-1]           # 2D image array, same as x-ray of chest with shape (110,110)\n",
        "    print(s)     \n",
        "    return views, img_2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX750rPEN-rL"
      },
      "source": [
        "Next step is data preprocessing.                                                \n",
        "Remove the highly correlated columns from the every slices and keep the remaining."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX0XdQ8Bjws7"
      },
      "source": [
        "def get_correlation(data, threshold):     # prepares correlation metric for every slice and returns the correlated columns with correlation higher than a threshold\n",
        "    corr_col = set()\n",
        "    corr = data.corr()\n",
        "    for i in range(len(corr.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr.iloc[i,j]) > threshold:  #if abs(corr.iloc[i,j]) > threshold:\n",
        "                corr_col.add(corr.columns[i])\n",
        "    return corr_col\n",
        "\n",
        "def get_uncorr_data(train_data, test_data, threshold):     # created the block of inter-correlated columns and make dataframe of these columns with correlation value\n",
        "    start_time = time.time()\n",
        "    correlated_block = dict()\n",
        "    corr_columns = get_correlation(pd.DataFrame(train_data), threshold)\n",
        "    temp_correlated_block = dict()\n",
        "\n",
        "\n",
        "    corrmat = pd.DataFrame(train_data).corr()\n",
        "\n",
        "    corrdata = corrmat.stack().sort_values(ascending = False)  #corrdata = corrmat.abs().stack().sort_values(ascending = False)\n",
        "\n",
        "    corrdata = corrdata[corrdata > threshold]\n",
        "    corrdata = corrdata[corrdata <= 1]\n",
        "    corrdata = pd.DataFrame(corrdata).reset_index()\n",
        "    corrdata.columns = ['feature1','feature2', 'value']\n",
        "\n",
        "    grouped_column_list = []\n",
        "    correlated_group_list = []\n",
        "    for column in corrdata['feature1']:\n",
        "        if column not in grouped_column_list:\n",
        "            correlated_block_list = corrdata[corrdata.feature1 == column]\n",
        "            grouped_column_list = grouped_column_list + list(correlated_block_list.feature2.unique()) + [column]\n",
        "            correlated_group_list.append(correlated_block_list)         #  inter-correlated_block\n",
        "    # if we drop all inter-correlated columns, data will lost its purity\n",
        "    # so we will take out 1 column from every correlated block and would not drop it.\n",
        "    # this will help in reducing the complexity of data without reducing its purity.\n",
        "    important_columns = []\n",
        "    for data in correlated_group_list:\n",
        "        columns = list(data.feature1.unique()) + list(data.feature2.unique())\n",
        "        important_columns.append(columns[0])                      # Selecting 1 column from every inter-correlated block\n",
        "            \n",
        "\n",
        "    new_to_drop = list(corr_columns - set(important_columns))\n",
        "\n",
        "    l = new_to_drop\n",
        "    \n",
        "    # Also, as we will try to predict droped column from remaining. KNN seems to be good and time efficient algo.\n",
        "    # As KNN predicts from nearby columns, so atleast 2 nearby columns from droped colunmns sholuld be there.\n",
        "    # i.e. if 5th column is droped (3,4,6,7) should be there in available data.\n",
        "    columns_to_drop = list()\n",
        "    for i in l:\n",
        "        if i not in [0,1,108,109]:\n",
        "            if (i-1 not in columns_to_drop and i+1 not in columns_to_drop):     ####\n",
        "                if (i-2 not in columns_to_drop and i+2 not in columns_to_drop):\n",
        "                    columns_to_drop.append(int(i))\n",
        "\n",
        "    for col in columns_to_drop:\n",
        "        corr_col = corrdata[corrdata.feature1 == col]\n",
        "        temp_correlated_block =  list(corr_col.feature2.unique())\n",
        "        correlated_block[str(col)] = temp_correlated_block\n",
        "\n",
        "    col_to_drop_df = pd.concat([corrdata, pd.Series(columns_to_drop, name = 'column_to_drop')], axis = 1)\n",
        "    print(f'time for get_uncorr_data : {time.time() - start_time}')\n",
        "    \n",
        "    return col_to_drop_df, correlated_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxr_olF9j2z9"
      },
      "source": [
        "def get_cross_val_score(col_to_drop, y_0, correlated_block): \n",
        "    start_time = time.time()   \n",
        "    rf_score_mean = list()      # diff_1 = droped_col[i] - droped_col[i-1]                             \n",
        "    knn_score_mean = list()     # diff_2 = droped_col[i+1] - droped_col[i] - 1\n",
        "    knn_neighbors = list()      # training_col = imp_col[diff_1:-diff_2]\n",
        "    neighbors = 2\n",
        "    estimators = 60\n",
        "\n",
        "    # train the KNeighborsRegressor algo to make the predictions. The trained model can be saved to make predictions in future.\n",
        "    temp_y = y_0.reshape((len(y_0)*110, 110))\n",
        "    for key, value in correlated_block.items():\n",
        "        #rf = RandomForestRegressor(n_estimators=40, random_state=0)   # + y_0[0][:,j:j+1]\n",
        "        #rf_score_mean.append(cross_val_score(rf, pd.DataFrame(temp_y)[value], pd.DataFrame(temp_y)[int(key)]).mean()*100)\n",
        "        #knn_time = time.time()\n",
        "        knn_val_score = cross_val_score(KNeighborsRegressor(n_neighbors=2), pd.DataFrame(temp_y)[value], pd.DataFrame(temp_y)[int(key)])\n",
        "\n",
        "        mean = knn_val_score.mean()*100\n",
        "        m = list()\n",
        "        n = list()\n",
        "        p = list()\n",
        "        if mean < 0.995:\n",
        "            for k, o in enumerate([4, 6, 8, 10, 12]):           # selcet the best number pf neighbours if accuracy is less than 99.5%\n",
        "                scr = cross_val_score(KNeighborsRegressor(n_neighbors=o), pd.DataFrame(temp_y)[value], pd.DataFrame(temp_y)[int(key)])\n",
        "                m.append(o)\n",
        "                n.append(scr.mean())\n",
        "                p.append(scr)\n",
        "            max_arg = np.array(n).argmax()\n",
        "            knn_neighbors.append(m[max_arg])\n",
        "            mean = n[max_arg]*100\n",
        "        else:\n",
        "            knn_neighbors.append(2)\n",
        "        knn_score_mean.append(mean)\n",
        "\n",
        "    # for i, j in enumerate(col_to_drop):\n",
        "    #     rf = RandomForestRegressor(n_estimators=40, random_state=0)\n",
        "    #     rf_score_mean.append(np.array(cross_val_score(rf, pd.DataFrame(y_0[0])[imp_col[i]] + y_0[0][:,j:j+1], pd.DataFrame(y_0[0])[j])).mean()*100)\n",
        "    #     knn_val_score = cross_val_score(KNeighborsRegressor(n_neighbors=neighbors), pd.DataFrame(y_0[0])[imp_col[i]] + y_0[0][:,j:j+1], pd.DataFrame(y_0[0])[j])\n",
        "    #     mean = knn_val_score.mean()*100\n",
        "    #     m = list()\n",
        "    #     n = list()\n",
        "    #     p = list()\n",
        "    #     if mean < 0.95:\n",
        "    #         for k, o in enumerate([4, 6, 8, 10,12, 24]):\n",
        "    #             scr = cross_val_score(KNeighborsRegressor(n_neighbors=o), pd.DataFrame(y_0[0])[imp_col[i]] + y_0[0][:, j:j+1], pd.DataFrame(y_0[0])[j])\n",
        "    #             m.append(o)\n",
        "    #             n.append(scr.mean())\n",
        "    #             p.append(scr)\n",
        "    #         max_arg = np.array(n).argmax()\n",
        "    #         knn_neighbors.append(m[max_arg])\n",
        "    #         mean = n[max_arg]*100\n",
        "    #     else:\n",
        "    #         knn_neighbors.append(2)\n",
        "    #     knn_score_mean.append(mean)\n",
        "    print(f'time for get_cross_val_score : {time.time() - start_time}')\n",
        "    return  rf_score_mean, knn_score_mean, knn_neighbors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk2EnpE0kjTq"
      },
      "source": [
        "# now we will drop top 22 best correlated columns from the remaining columns selected as highly correlatewd based on the accuracy score made during prediction.\n",
        "# The process is simple, sort the columns based on accuracy score made in descending oreder and drop the top 22. Now the droped 22 can be predicted with high accuracy\n",
        "\n",
        "# After that it will return the data to be used for training.\n",
        "\n",
        "def get_model_to_predict_col(y_train_0, y_test_0, y0, threshold):      # here y0 = y_train_0 + y_test_0   (i.e complete data)\n",
        "    start_time = time.time()\n",
        "    new_correlated_block = list()\n",
        "    all_slices_knn_score = list()\n",
        "    all_slices_rf_score = list()\n",
        "    all_droped_col = list()\n",
        "    all_algo = list()\n",
        "    all_knn_neighbours = dict()\n",
        "    len_sel_col = list()           \n",
        "    len_droped_col = list()\n",
        "    y_train = np.empty((len(y_train_0),110,88,110))\n",
        "    y_test = np.empty((len(y_test_0),110,88,110))\n",
        "    for s in range(0,110):\n",
        "        print(f'slice {s} started......')\n",
        "        y_0 = y_train_0[:,:,:,s]\n",
        "        y_test0 = y_test_0[:,:,:,s]\n",
        "        col_to_drop_df, correlated_block = get_uncorr_data(y_0[4], y_test0[4], threshold)                                                    # get_uncorr_data\n",
        "        col_to_drop = list(col_to_drop_df.dropna().sort_values(by = 'value', ascending=False)['column_to_drop'])\n",
        "        col_to_drop = [int(i) for i in col_to_drop]\n",
        "        col_to_drop.sort()\n",
        "        len_sel_col.append(len(col_to_drop))\n",
        "        # imp_col = list()\n",
        "        # for i in np.arange(2,108):\n",
        "        #     if i in col_to_drop:\n",
        "        #         imp_col.append([i-2,i-1,i+1,i+2])\n",
        " \n",
        "        rf_score_mean, knn_score_mean, knn_neighbors = get_cross_val_score(col_to_drop, y0[:,:,:,s], correlated_block)         # get_cross_val_score \n",
        "        #score_df = pd.DataFrame({'col_to_drop' : col_to_drop, 'rf_score_mean' : rf_score_mean, 'knn_score_mean' : knn_score_mean})\n",
        "        score_df = pd.DataFrame({'col_to_drop' : col_to_drop, 'knn_score_mean' : knn_score_mean})\n",
        "        # if np.mean(score_df.knn_score_mean) > np.mean(score_df.rf_score_mean):\n",
        "        #     scoring_algo = 'knn_score_mean' \n",
        "        #     all_knn_neighbours[str(s)] = knn_neighbors\n",
        "        # else:        \n",
        "        #     scoring_algo = 'rf_score_mean'\n",
        "\n",
        "        # all_algo.append(scoring_algo)\n",
        "        # droped_col = list(score_df.sort_values(by=scoring_algo, ascending=False)['col_to_drop'])[:22]\n",
        "        droped_col = list(score_df.sort_values(by='knn_score_mean', ascending=False)['col_to_drop'])[:22]   # sorting in descending order and select top 22\n",
        "        droped_col.sort()\n",
        "        temp_correlated_block = dict()\n",
        "        for col in droped_col:\n",
        "            if str(col) in correlated_block.keys():\n",
        "                temp_correlated_block[str(col)] = correlated_block[str(col)]\n",
        "        new_correlated_block.append(temp_correlated_block)\n",
        "        all_droped_col.append(droped_col)\n",
        "        print(f'columns selected to drop : {len(col_to_drop)} and   {len(droped_col)} are droped')\n",
        "        all_slices_knn_score.append(knn_score_mean)\n",
        "        all_slices_rf_score.append(rf_score_mean)\n",
        "\n",
        "        #y_train[:,:,:s] = pd.DataFrame(y_0).drop(droped_col, axis = 1)\n",
        "        #y_test[:,:,:s] = pd.DataFrame(y_test0).drop(droped_col, axis = 1)\n",
        "        for z in range(len(y_train_0)):\n",
        "            y_train[z,:,:,s] = np.array(pd.DataFrame(y_0[z]).drop(droped_col, axis = 1)).reshape(110,88)\n",
        "        for z in range(len(y_test0)):\n",
        "            y_test[z,:,:,s] = np.array(pd.DataFrame(y_test0[z]).drop(droped_col, axis = 1)).reshape(110,88)\n",
        "\n",
        "        print(f'total time required : {time.time() - start_time}', '\\n')\n",
        "    return y_train, y_test, all_slices_knn_score, all_slices_rf_score, all_droped_col, all_algo, all_knn_neighbours, new_correlated_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smkkMzc3NSGh"
      },
      "source": [
        "# as the model requires huge amount of data for training \n",
        "\n",
        "# after we have cleaned data, we will perform data augmentation\n",
        "\n",
        "# due to liminted hardware, we can affort to creat 10 new images from 1 image.\n",
        "\n",
        "# This function will return the well maintained training data afer performing Augmentation\n",
        "\n",
        "def get_augmented_data(len_train_data, y_aug):         # len_train_data = 65\n",
        "    x = np.empty((len_train_data*10, 110,88))\n",
        "    y = np.empty((len_train_data*10, 110,88,110))\n",
        "    s = 0\n",
        "    k = 0\n",
        "    for i in y_aug:    # i.shape = 7150*110*110*1        65*110 = 7150\n",
        "        k +=1\n",
        "        print(k)\n",
        "        s1 = 0\n",
        "        s2 = 110\n",
        "        for j in range(65):\n",
        "            temp_y = np.empty((110,88,110))\n",
        "            for m in range(110):                 # temp_x.shape = [110,110,110]         \n",
        "                count = j*110 + m\n",
        "                y_temp = i[count].reshape(110,88)\n",
        "                temp_y[:,:,m] = y_temp\n",
        "            # temp_y = i[s1:s2].reshape(110,110,110)\n",
        "            y[j*k,:,:,:] = temp_y\n",
        "            s1 = s1+110\n",
        "            s2 = s2+110\n",
        "            x_temp = temp_y[55,:,:].T\n",
        "            x[s] = x_temp[::-1]\n",
        "            s += 1\n",
        "        if k >= 10:\n",
        "            break\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5fExI9U9ORw"
      },
      "source": [
        "def r_squared(x,y):\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  slope, intercept, r_value, p_value, std_error = scipy.stats.linregress(x,y)\n",
        "  r_value = tf.TensorArray(r_value)\n",
        "  return r_value**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU2HaXgYknrU"
      },
      "source": [
        "# functions to plot the learning curve\n",
        "def plot_learning_curve(model_history):   \n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.plot(model_history.history['accuracy'], color = 'green', label = 'train_accuracy')                         # np.arange(0,epochs),\n",
        "    plt.plot(model_history.history['loss'], color = 'red', label = 'train_loss')\n",
        "    plt.plot(model_history.history['val_accuracy'], color = 'blue', label = 'test_accuracy')\n",
        "    plt.plot(model_history.history['val_loss'], color = 'black', label = 'test_loss')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.xlabel('no. of epochs')\n",
        "    plt.ylabel('accuracy and loss')\n",
        "    plt.legend(loc = 'lower right')\n",
        "\n",
        "def plot_accuracy_curve(model_history):    \n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.plot(model_history.history['accuracy'], color = 'green', label='accuracy')\n",
        "    plt.plot(model_history.history['val_accuracy'], color = 'red', label = 'test accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.legend(loc = 'lower right')\n",
        "\n",
        "def plot_loss_curve(model_history):\n",
        "    plt.figure(figsize = (20,7))\n",
        "    plt.plot(model_history.history['loss'], color = 'green', label = 'train_loss')\n",
        "    plt.plot(model_history.history['val_loss'], color = 'red', label = 'val_loss')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhnEzJ8wkq9z"
      },
      "source": [
        "patients_id = os.listdir('/content/CT_Scans/EXP1_blind')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlc864Jzkt3z"
      },
      "source": [
        "df = pd.read_csv('/content/Response EXP1 - AI_patients.csv')\n",
        "fm_id = list(df[df['type'] == 'FM']['id'].values)\n",
        "fb_id = list(df[df['type'] == 'FB']['id'].values)\n",
        "tm_id = list(df[df['type'] == 'TM']['id'].values)\n",
        "tb_id = list(df[df['type'] == 'TB']['id'].values)\n",
        "fm_id = [str(i) for i in fm_id]\n",
        "fb_id = [str(i) for i in fb_id]\n",
        "tm_id = [str(i) for i in tm_id]\n",
        "tb_id = [str(i) for i in tb_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHG9MdIvkxDL",
        "outputId": "391527d8-b0db-4676-d989-2d577e06459c"
      },
      "source": [
        "f = patients_id.copy()\n",
        "g2d_0 = np.zeros((len(f),110,110))\n",
        "views_0 = np.zeros((len(f),110,110,110))\n",
        "fcount_0 = []\n",
        "for i,j in enumerate(f):\n",
        "    print(i)\n",
        "    img_3d, img_2d = get_data(j, no_crop)\n",
        "    g2d_0[i] = img_2d\n",
        "    views_0[i] = img_3d\n",
        "    #views_0[i] = selected_slices(j, no_crop)\n",
        "x_0 = g2d_0\n",
        "y_0 = views_0\n",
        "np.save('/content/Data_out_0.npy', views_0)              # Temprory storing the data in drive\n",
        "np.save('/content/Data_in_0.npy', g2d_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "1\n",
            "4\n",
            "1\n",
            "5\n",
            "1\n",
            "6\n",
            "1\n",
            "7\n",
            "1\n",
            "8\n",
            "1\n",
            "9\n",
            "1\n",
            "10\n",
            "0\n",
            "11\n",
            "1\n",
            "12\n",
            "1\n",
            "13\n",
            "1\n",
            "14\n",
            "1\n",
            "15\n",
            "1\n",
            "16\n",
            "1\n",
            "17\n",
            "1\n",
            "18\n",
            "1\n",
            "19\n",
            "1\n",
            "20\n",
            "1\n",
            "21\n",
            "1\n",
            "22\n",
            "1\n",
            "23\n",
            "1\n",
            "24\n",
            "1\n",
            "25\n",
            "0\n",
            "26\n",
            "1\n",
            "27\n",
            "1\n",
            "28\n",
            "1\n",
            "29\n",
            "1\n",
            "30\n",
            "1\n",
            "31\n",
            "1\n",
            "32\n",
            "1\n",
            "33\n",
            "1\n",
            "34\n",
            "1\n",
            "35\n",
            "1\n",
            "36\n",
            "1\n",
            "37\n",
            "1\n",
            "38\n",
            "1\n",
            "39\n",
            "1\n",
            "40\n",
            "1\n",
            "41\n",
            "1\n",
            "42\n",
            "0\n",
            "43\n",
            "1\n",
            "44\n",
            "0\n",
            "45\n",
            "1\n",
            "46\n",
            "1\n",
            "47\n",
            "1\n",
            "48\n",
            "1\n",
            "49\n",
            "1\n",
            "50\n",
            "1\n",
            "51\n",
            "1\n",
            "52\n",
            "1\n",
            "53\n",
            "1\n",
            "54\n",
            "1\n",
            "55\n",
            "1\n",
            "56\n",
            "1\n",
            "57\n",
            "1\n",
            "58\n",
            "1\n",
            "59\n",
            "1\n",
            "60\n",
            "1\n",
            "61\n",
            "1\n",
            "62\n",
            "1\n",
            "63\n",
            "1\n",
            "64\n",
            "1\n",
            "65\n",
            "1\n",
            "66\n",
            "1\n",
            "67\n",
            "1\n",
            "68\n",
            "0\n",
            "69\n",
            "1\n",
            "70\n",
            "1\n",
            "71\n",
            "1\n",
            "72\n",
            "1\n",
            "73\n",
            "1\n",
            "74\n",
            "1\n",
            "75\n",
            "1\n",
            "76\n",
            "1\n",
            "77\n",
            "1\n",
            "78\n",
            "1\n",
            "79\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piWWG8WBk31X",
        "outputId": "b40c99f2-c90d-4ca1-d930-87c189ce0fb6"
      },
      "source": [
        "f = patients_id.copy()\n",
        "g2d_1 = np.zeros((80,110,110))\n",
        "views_1 = np.zeros((80,110,110,110))\n",
        "for i,j in enumerate(f):\n",
        "    print(i)\n",
        "    img_3d, img_2d = get_data(j, crop_the_image_1)\n",
        "    g2d_1[i] = img_2d\n",
        "    views_1[i] = img_3d\n",
        "    #views_0[i] = selected_slices(j, no_crop)\n",
        "x_1 = g2d_1\n",
        "y_1 = views_1\n",
        "np.save('Data_out_1.npy', views_1)\n",
        "np.save('Data_in_1.npy', g2d_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "1\n",
            "4\n",
            "1\n",
            "5\n",
            "1\n",
            "6\n",
            "1\n",
            "7\n",
            "1\n",
            "8\n",
            "1\n",
            "9\n",
            "1\n",
            "10\n",
            "0\n",
            "11\n",
            "1\n",
            "12\n",
            "1\n",
            "13\n",
            "1\n",
            "14\n",
            "1\n",
            "15\n",
            "1\n",
            "16\n",
            "1\n",
            "17\n",
            "1\n",
            "18\n",
            "1\n",
            "19\n",
            "1\n",
            "20\n",
            "1\n",
            "21\n",
            "1\n",
            "22\n",
            "1\n",
            "23\n",
            "1\n",
            "24\n",
            "1\n",
            "25\n",
            "0\n",
            "26\n",
            "1\n",
            "27\n",
            "1\n",
            "28\n",
            "1\n",
            "29\n",
            "1\n",
            "30\n",
            "1\n",
            "31\n",
            "1\n",
            "32\n",
            "1\n",
            "33\n",
            "1\n",
            "34\n",
            "1\n",
            "35\n",
            "1\n",
            "36\n",
            "1\n",
            "37\n",
            "1\n",
            "38\n",
            "1\n",
            "39\n",
            "1\n",
            "40\n",
            "1\n",
            "41\n",
            "1\n",
            "42\n",
            "0\n",
            "43\n",
            "1\n",
            "44\n",
            "0\n",
            "45\n",
            "1\n",
            "46\n",
            "1\n",
            "47\n",
            "1\n",
            "48\n",
            "1\n",
            "49\n",
            "1\n",
            "50\n",
            "1\n",
            "51\n",
            "1\n",
            "52\n",
            "1\n",
            "53\n",
            "1\n",
            "54\n",
            "1\n",
            "55\n",
            "1\n",
            "56\n",
            "1\n",
            "57\n",
            "1\n",
            "58\n",
            "1\n",
            "59\n",
            "1\n",
            "60\n",
            "1\n",
            "61\n",
            "1\n",
            "62\n",
            "1\n",
            "63\n",
            "1\n",
            "64\n",
            "1\n",
            "65\n",
            "1\n",
            "66\n",
            "1\n",
            "67\n",
            "1\n",
            "68\n",
            "0\n",
            "69\n",
            "1\n",
            "70\n",
            "1\n",
            "71\n",
            "1\n",
            "72\n",
            "1\n",
            "73\n",
            "1\n",
            "74\n",
            "1\n",
            "75\n",
            "1\n",
            "76\n",
            "1\n",
            "77\n",
            "1\n",
            "78\n",
            "1\n",
            "79\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFX28jIAk7aA"
      },
      "source": [
        "x_0 = np.load('/content/Data_in_0.npy')\n",
        "y_0 = np.load('/content/Data_out_0.npy')\n",
        "x_1 = np.load('/content/Data_in_1.npy')\n",
        "y_1 = np.load('/content/Data_out_1.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jzE5_FhlsaD"
      },
      "source": [
        "x_train_0 = x_1[:65]\n",
        "x_test_0 = x_1[65:]\n",
        "y_train_0 = y_1[:65]\n",
        "y_test_0 = y_1[65:]\n",
        "\n",
        "#x0 = x_train_0[:,1,:]\n",
        "#y0 = y_train_0[:,:,:,1]          # temp_x = x_0[:][:,1,:], temp_y = y_0[:][:,:,:,1]\n",
        "#x_test0 = x_test_0[:,1,:]\n",
        "#y_test0 = y_test_0[:,:,:,1]\n",
        "x_train_1 = x_1[:65]\n",
        "x_test_1 = x_1[65:]\n",
        "y_train_1 = y_1[:65]\n",
        "y_test_1 = y_1[65:]\n",
        "\n",
        "#x1 = x_train_1[:,1,:]\n",
        "#y1 = y_train_1[:,:,:,1]\n",
        "#x_test1 = x_test_1[:,1,:]\n",
        "#y_test1 = y_test_1[:,:,:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRijPGVlKhR",
        "outputId": "6f67ce77-0a22-42df-8790-65ac4284de16"
      },
      "source": [
        "y_train, y_test,all_slices_knn_score, all_slices_rf_score, all_droped_col, all_algo, all_knn_neighbours, new_correlated_block = get_model_to_predict_col(y_train_0, y_test_0, y_0, 0.92)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "slice 0 started......\n",
            "time for get_uncorr_data : 0.39174890518188477\n",
            "time for get_cross_val_score : 5.17595648765564\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 6.231240749359131 \n",
            "\n",
            "slice 1 started......\n",
            "time for get_uncorr_data : 0.22116613388061523\n",
            "time for get_cross_val_score : 5.128057241439819\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 11.668787002563477 \n",
            "\n",
            "slice 2 started......\n",
            "time for get_uncorr_data : 0.2226855754852295\n",
            "time for get_cross_val_score : 5.576344013214111\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 17.554834365844727 \n",
            "\n",
            "slice 3 started......\n",
            "time for get_uncorr_data : 0.20875215530395508\n",
            "time for get_cross_val_score : 5.950806617736816\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 23.80675959587097 \n",
            "\n",
            "slice 4 started......\n",
            "time for get_uncorr_data : 0.22080588340759277\n",
            "time for get_cross_val_score : 6.817502975463867\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 30.932684183120728 \n",
            "\n",
            "slice 5 started......\n",
            "time for get_uncorr_data : 0.21672511100769043\n",
            "time for get_cross_val_score : 6.745067834854126\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 37.982287645339966 \n",
            "\n",
            "slice 6 started......\n",
            "time for get_uncorr_data : 0.19957637786865234\n",
            "time for get_cross_val_score : 6.551594972610474\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 44.825281381607056 \n",
            "\n",
            "slice 7 started......\n",
            "time for get_uncorr_data : 0.2114114761352539\n",
            "time for get_cross_val_score : 6.127246141433716\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 51.25565814971924 \n",
            "\n",
            "slice 8 started......\n",
            "time for get_uncorr_data : 0.2126624584197998\n",
            "time for get_cross_val_score : 6.293953895568848\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 57.85119032859802 \n",
            "\n",
            "slice 9 started......\n",
            "time for get_uncorr_data : 0.20406198501586914\n",
            "time for get_cross_val_score : 7.122920274734497\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 65.27184581756592 \n",
            "\n",
            "slice 10 started......\n",
            "time for get_uncorr_data : 0.20497608184814453\n",
            "time for get_cross_val_score : 7.567201375961304\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 73.14170908927917 \n",
            "\n",
            "slice 11 started......\n",
            "time for get_uncorr_data : 0.21408629417419434\n",
            "time for get_cross_val_score : 8.351929187774658\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 81.80626916885376 \n",
            "\n",
            "slice 12 started......\n",
            "time for get_uncorr_data : 0.22803521156311035\n",
            "time for get_cross_val_score : 8.273846626281738\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 90.40667486190796 \n",
            "\n",
            "slice 13 started......\n",
            "time for get_uncorr_data : 0.20413732528686523\n",
            "time for get_cross_val_score : 9.025497198104858\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 99.73151445388794 \n",
            "\n",
            "slice 14 started......\n",
            "time for get_uncorr_data : 0.22237586975097656\n",
            "time for get_cross_val_score : 9.396440744400024\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 109.44127321243286 \n",
            "\n",
            "slice 15 started......\n",
            "time for get_uncorr_data : 0.2214655876159668\n",
            "time for get_cross_val_score : 9.3533935546875\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 119.11200094223022 \n",
            "\n",
            "slice 16 started......\n",
            "time for get_uncorr_data : 0.20046687126159668\n",
            "time for get_cross_val_score : 8.25497317314148\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 127.65498948097229 \n",
            "\n",
            "slice 17 started......\n",
            "time for get_uncorr_data : 0.19965076446533203\n",
            "time for get_cross_val_score : 7.484433650970459\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 135.4292631149292 \n",
            "\n",
            "slice 18 started......\n",
            "time for get_uncorr_data : 0.2081289291381836\n",
            "time for get_cross_val_score : 6.453503131866455\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 142.19484162330627 \n",
            "\n",
            "slice 19 started......\n",
            "time for get_uncorr_data : 0.22576642036437988\n",
            "time for get_cross_val_score : 5.943421363830566\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 148.45029544830322 \n",
            "\n",
            "slice 20 started......\n",
            "time for get_uncorr_data : 0.21437931060791016\n",
            "time for get_cross_val_score : 5.524638891220093\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 154.27777743339539 \n",
            "\n",
            "slice 21 started......\n",
            "time for get_uncorr_data : 0.22537851333618164\n",
            "time for get_cross_val_score : 5.228538274765015\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 159.81793403625488 \n",
            "\n",
            "slice 22 started......\n",
            "time for get_uncorr_data : 0.2104179859161377\n",
            "time for get_cross_val_score : 4.965047359466553\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 165.07803750038147 \n",
            "\n",
            "slice 23 started......\n",
            "time for get_uncorr_data : 0.2145226001739502\n",
            "time for get_cross_val_score : 5.196965456008911\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 170.58167624473572 \n",
            "\n",
            "slice 24 started......\n",
            "time for get_uncorr_data : 0.213881254196167\n",
            "time for get_cross_val_score : 4.738701581954956\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 175.62732529640198 \n",
            "\n",
            "slice 25 started......\n",
            "time for get_uncorr_data : 0.2137925624847412\n",
            "time for get_cross_val_score : 4.412067174911499\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 180.34670066833496 \n",
            "\n",
            "slice 26 started......\n",
            "time for get_uncorr_data : 0.22821331024169922\n",
            "time for get_cross_val_score : 3.9194839000701904\n",
            "columns selected to drop : 28 and   22 are droped\n",
            "total time required : 184.5830249786377 \n",
            "\n",
            "slice 27 started......\n",
            "time for get_uncorr_data : 0.2236025333404541\n",
            "time for get_cross_val_score : 3.8159759044647217\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 188.7102551460266 \n",
            "\n",
            "slice 28 started......\n",
            "time for get_uncorr_data : 0.21151113510131836\n",
            "time for get_cross_val_score : 3.9267737865448\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 192.9397735595703 \n",
            "\n",
            "slice 29 started......\n",
            "time for get_uncorr_data : 0.22982549667358398\n",
            "time for get_cross_val_score : 3.963820695877075\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 197.22373723983765 \n",
            "\n",
            "slice 30 started......\n",
            "time for get_uncorr_data : 0.20425748825073242\n",
            "time for get_cross_val_score : 4.030172824859619\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 201.54721188545227 \n",
            "\n",
            "slice 31 started......\n",
            "time for get_uncorr_data : 0.20176362991333008\n",
            "time for get_cross_val_score : 3.7546677589416504\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 205.5927608013153 \n",
            "\n",
            "slice 32 started......\n",
            "time for get_uncorr_data : 0.20534396171569824\n",
            "time for get_cross_val_score : 4.128269195556641\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 210.0157506465912 \n",
            "\n",
            "slice 33 started......\n",
            "time for get_uncorr_data : 0.21684002876281738\n",
            "time for get_cross_val_score : 4.260995864868164\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 214.5798258781433 \n",
            "\n",
            "slice 34 started......\n",
            "time for get_uncorr_data : 0.21229767799377441\n",
            "time for get_cross_val_score : 4.0329062938690186\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 218.91009378433228 \n",
            "\n",
            "slice 35 started......\n",
            "time for get_uncorr_data : 0.20935487747192383\n",
            "time for get_cross_val_score : 4.113768100738525\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 223.3276014328003 \n",
            "\n",
            "slice 36 started......\n",
            "time for get_uncorr_data : 0.21138930320739746\n",
            "time for get_cross_val_score : 4.320377826690674\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 227.94410967826843 \n",
            "\n",
            "slice 37 started......\n",
            "time for get_uncorr_data : 0.2112133502960205\n",
            "time for get_cross_val_score : 4.485425233840942\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 232.72829151153564 \n",
            "\n",
            "slice 38 started......\n",
            "time for get_uncorr_data : 0.2151944637298584\n",
            "time for get_cross_val_score : 4.738250255584717\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 237.76614356040955 \n",
            "\n",
            "slice 39 started......\n",
            "time for get_uncorr_data : 0.207871675491333\n",
            "time for get_cross_val_score : 4.984428882598877\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 243.05030584335327 \n",
            "\n",
            "slice 40 started......\n",
            "time for get_uncorr_data : 0.22365117073059082\n",
            "time for get_cross_val_score : 5.137457847595215\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 248.49689722061157 \n",
            "\n",
            "slice 41 started......\n",
            "time for get_uncorr_data : 0.227891206741333\n",
            "time for get_cross_val_score : 5.199130296707153\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 254.0223467350006 \n",
            "\n",
            "slice 42 started......\n",
            "time for get_uncorr_data : 0.2198197841644287\n",
            "time for get_cross_val_score : 5.204777002334595\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 259.5358364582062 \n",
            "\n",
            "slice 43 started......\n",
            "time for get_uncorr_data : 0.19946050643920898\n",
            "time for get_cross_val_score : 5.156557559967041\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 264.9814989566803 \n",
            "\n",
            "slice 44 started......\n",
            "time for get_uncorr_data : 0.21575045585632324\n",
            "time for get_cross_val_score : 4.901569366455078\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 270.1874854564667 \n",
            "\n",
            "slice 45 started......\n",
            "time for get_uncorr_data : 0.22243666648864746\n",
            "time for get_cross_val_score : 4.886354446411133\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 275.38335132598877 \n",
            "\n",
            "slice 46 started......\n",
            "time for get_uncorr_data : 0.20212054252624512\n",
            "time for get_cross_val_score : 4.606301307678223\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 280.2759642601013 \n",
            "\n",
            "slice 47 started......\n",
            "time for get_uncorr_data : 0.22081518173217773\n",
            "time for get_cross_val_score : 4.153290271759033\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 284.7370533943176 \n",
            "\n",
            "slice 48 started......\n",
            "time for get_uncorr_data : 0.21211576461791992\n",
            "time for get_cross_val_score : 4.084789276123047\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 289.1217212677002 \n",
            "\n",
            "slice 49 started......\n",
            "time for get_uncorr_data : 0.2120370864868164\n",
            "time for get_cross_val_score : 4.398092746734619\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 293.8175628185272 \n",
            "\n",
            "slice 50 started......\n",
            "time for get_uncorr_data : 0.21017694473266602\n",
            "time for get_cross_val_score : 4.486630439758301\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 298.60144901275635 \n",
            "\n",
            "slice 51 started......\n",
            "time for get_uncorr_data : 0.2087094783782959\n",
            "time for get_cross_val_score : 4.603748798370361\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 303.5074484348297 \n",
            "\n",
            "slice 52 started......\n",
            "time for get_uncorr_data : 0.2126789093017578\n",
            "time for get_cross_val_score : 4.25910496711731\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 308.07262897491455 \n",
            "\n",
            "slice 53 started......\n",
            "time for get_uncorr_data : 0.22581052780151367\n",
            "time for get_cross_val_score : 4.341789484024048\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 312.73168182373047 \n",
            "\n",
            "slice 54 started......\n",
            "time for get_uncorr_data : 0.21375441551208496\n",
            "time for get_cross_val_score : 4.485245943069458\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 317.5211217403412 \n",
            "\n",
            "slice 55 started......\n",
            "time for get_uncorr_data : 0.21625304222106934\n",
            "time for get_cross_val_score : 4.768198490142822\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 322.5948486328125 \n",
            "\n",
            "slice 56 started......\n",
            "time for get_uncorr_data : 0.219010591506958\n",
            "time for get_cross_val_score : 4.256318092346191\n",
            "columns selected to drop : 29 and   22 are droped\n",
            "total time required : 327.1581766605377 \n",
            "\n",
            "slice 57 started......\n",
            "time for get_uncorr_data : 0.21633100509643555\n",
            "time for get_cross_val_score : 4.710245370864868\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 332.1754786968231 \n",
            "\n",
            "slice 58 started......\n",
            "time for get_uncorr_data : 0.22897815704345703\n",
            "time for get_cross_val_score : 4.843589782714844\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 337.33956694602966 \n",
            "\n",
            "slice 59 started......\n",
            "time for get_uncorr_data : 0.221663236618042\n",
            "time for get_cross_val_score : 4.917366027832031\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 342.56753611564636 \n",
            "\n",
            "slice 60 started......\n",
            "time for get_uncorr_data : 0.2168271541595459\n",
            "time for get_cross_val_score : 5.598540544509888\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 348.48152446746826 \n",
            "\n",
            "slice 61 started......\n",
            "time for get_uncorr_data : 0.27492213249206543\n",
            "time for get_cross_val_score : 5.61772346496582\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 354.49131059646606 \n",
            "\n",
            "slice 62 started......\n",
            "time for get_uncorr_data : 0.25122690200805664\n",
            "time for get_cross_val_score : 6.076762676239014\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 360.9391405582428 \n",
            "\n",
            "slice 63 started......\n",
            "time for get_uncorr_data : 0.24239897727966309\n",
            "time for get_cross_val_score : 4.91085958480835\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 366.19307136535645 \n",
            "\n",
            "slice 64 started......\n",
            "time for get_uncorr_data : 0.23595380783081055\n",
            "time for get_cross_val_score : 4.709065198898315\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 371.22376561164856 \n",
            "\n",
            "slice 65 started......\n",
            "time for get_uncorr_data : 0.22241902351379395\n",
            "time for get_cross_val_score : 4.698917627334595\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 376.2316722869873 \n",
            "\n",
            "slice 66 started......\n",
            "time for get_uncorr_data : 0.22314047813415527\n",
            "time for get_cross_val_score : 5.124749183654785\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 381.6712510585785 \n",
            "\n",
            "slice 67 started......\n",
            "time for get_uncorr_data : 0.2159888744354248\n",
            "time for get_cross_val_score : 5.12639307975769\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 387.1011595726013 \n",
            "\n",
            "slice 68 started......\n",
            "time for get_uncorr_data : 0.21617889404296875\n",
            "time for get_cross_val_score : 4.617063283920288\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 392.0215561389923 \n",
            "\n",
            "slice 69 started......\n",
            "time for get_uncorr_data : 0.21511268615722656\n",
            "time for get_cross_val_score : 4.756856679916382\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 397.082692861557 \n",
            "\n",
            "slice 70 started......\n",
            "time for get_uncorr_data : 0.2210862636566162\n",
            "time for get_cross_val_score : 4.997369050979614\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 402.3914933204651 \n",
            "\n",
            "slice 71 started......\n",
            "time for get_uncorr_data : 0.22168278694152832\n",
            "time for get_cross_val_score : 6.885324716567993\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 409.78480195999146 \n",
            "\n",
            "slice 72 started......\n",
            "time for get_uncorr_data : 1.1340131759643555\n",
            "time for get_cross_val_score : 5.685512065887451\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 416.7101888656616 \n",
            "\n",
            "slice 73 started......\n",
            "time for get_uncorr_data : 0.21681523323059082\n",
            "time for get_cross_val_score : 5.240832805633545\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 422.2581629753113 \n",
            "\n",
            "slice 74 started......\n",
            "time for get_uncorr_data : 0.21443390846252441\n",
            "time for get_cross_val_score : 5.122739553451538\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 427.6868562698364 \n",
            "\n",
            "slice 75 started......\n",
            "time for get_uncorr_data : 0.2133939266204834\n",
            "time for get_cross_val_score : 5.225117444992065\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 433.21610593795776 \n",
            "\n",
            "slice 76 started......\n",
            "time for get_uncorr_data : 0.2174062728881836\n",
            "time for get_cross_val_score : 5.148511171340942\n",
            "columns selected to drop : 31 and   22 are droped\n",
            "total time required : 438.67781352996826 \n",
            "\n",
            "slice 77 started......\n",
            "time for get_uncorr_data : 0.22348451614379883\n",
            "time for get_cross_val_score : 5.190614700317383\n",
            "columns selected to drop : 30 and   22 are droped\n",
            "total time required : 444.18275356292725 \n",
            "\n",
            "slice 78 started......\n",
            "time for get_uncorr_data : 0.22838234901428223\n",
            "time for get_cross_val_score : 5.59850549697876\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 450.10450553894043 \n",
            "\n",
            "slice 79 started......\n",
            "time for get_uncorr_data : 0.2152717113494873\n",
            "time for get_cross_val_score : 6.173452854156494\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 456.5874891281128 \n",
            "\n",
            "slice 80 started......\n",
            "time for get_uncorr_data : 0.21160435676574707\n",
            "time for get_cross_val_score : 5.6582818031311035\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 462.54419803619385 \n",
            "\n",
            "slice 81 started......\n",
            "time for get_uncorr_data : 0.2066044807434082\n",
            "time for get_cross_val_score : 5.58545184135437\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 468.4215521812439 \n",
            "\n",
            "slice 82 started......\n",
            "time for get_uncorr_data : 0.19768190383911133\n",
            "time for get_cross_val_score : 5.839825391769409\n",
            "columns selected to drop : 32 and   22 are droped\n",
            "total time required : 474.54107999801636 \n",
            "\n",
            "slice 83 started......\n",
            "time for get_uncorr_data : 0.2000138759613037\n",
            "time for get_cross_val_score : 7.0924623012542725\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 481.9181344509125 \n",
            "\n",
            "slice 84 started......\n",
            "time for get_uncorr_data : 0.23038220405578613\n",
            "time for get_cross_val_score : 7.19727087020874\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 489.43635630607605 \n",
            "\n",
            "slice 85 started......\n",
            "time for get_uncorr_data : 0.20450854301452637\n",
            "time for get_cross_val_score : 8.203356266021729\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 497.9363179206848 \n",
            "\n",
            "slice 86 started......\n",
            "time for get_uncorr_data : 0.22959542274475098\n",
            "time for get_cross_val_score : 8.011426448822021\n",
            "columns selected to drop : 33 and   22 are droped\n",
            "total time required : 506.26448798179626 \n",
            "\n",
            "slice 87 started......\n",
            "time for get_uncorr_data : 0.22589874267578125\n",
            "time for get_cross_val_score : 9.544916868209839\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 516.1225006580353 \n",
            "\n",
            "slice 88 started......\n",
            "time for get_uncorr_data : 0.2107868194580078\n",
            "time for get_cross_val_score : 10.385095119476318\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 526.811304807663 \n",
            "\n",
            "slice 89 started......\n",
            "time for get_uncorr_data : 0.21691346168518066\n",
            "time for get_cross_val_score : 10.785530090332031\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 537.9088428020477 \n",
            "\n",
            "slice 90 started......\n",
            "time for get_uncorr_data : 0.22219133377075195\n",
            "time for get_cross_val_score : 12.70826506614685\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 550.9405741691589 \n",
            "\n",
            "slice 91 started......\n",
            "time for get_uncorr_data : 0.23443031311035156\n",
            "time for get_cross_val_score : 13.604505777359009\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 564.8795368671417 \n",
            "\n",
            "slice 92 started......\n",
            "time for get_uncorr_data : 0.21324896812438965\n",
            "time for get_cross_val_score : 14.330468654632568\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 579.5336811542511 \n",
            "\n",
            "slice 93 started......\n",
            "time for get_uncorr_data : 0.22336077690124512\n",
            "time for get_cross_val_score : 15.556415557861328\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 595.4068651199341 \n",
            "\n",
            "slice 94 started......\n",
            "time for get_uncorr_data : 0.209028959274292\n",
            "time for get_cross_val_score : 17.97704553604126\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 613.6836605072021 \n",
            "\n",
            "slice 95 started......\n",
            "time for get_uncorr_data : 0.22981548309326172\n",
            "time for get_cross_val_score : 19.989251375198364\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 633.9969832897186 \n",
            "\n",
            "slice 96 started......\n",
            "time for get_uncorr_data : 0.22895097732543945\n",
            "time for get_cross_val_score : 23.340105295181274\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 657.6722197532654 \n",
            "\n",
            "slice 97 started......\n",
            "time for get_uncorr_data : 0.23668932914733887\n",
            "time for get_cross_val_score : 30.309128284454346\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 688.3493399620056 \n",
            "\n",
            "slice 98 started......\n",
            "time for get_uncorr_data : 0.24159860610961914\n",
            "time for get_cross_val_score : 35.515347480773926\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 724.2155923843384 \n",
            "\n",
            "slice 99 started......\n",
            "time for get_uncorr_data : 0.2350912094116211\n",
            "time for get_cross_val_score : 47.22939109802246\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 771.7888469696045 \n",
            "\n",
            "slice 100 started......\n",
            "time for get_uncorr_data : 0.23595261573791504\n",
            "time for get_cross_val_score : 44.69303321838379\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 816.8680925369263 \n",
            "\n",
            "slice 101 started......\n",
            "time for get_uncorr_data : 0.22308588027954102\n",
            "time for get_cross_val_score : 38.404362201690674\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 855.5968806743622 \n",
            "\n",
            "slice 102 started......\n",
            "time for get_uncorr_data : 0.21675920486450195\n",
            "time for get_cross_val_score : 37.0920934677124\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 893.0116958618164 \n",
            "\n",
            "slice 103 started......\n",
            "time for get_uncorr_data : 0.21349596977233887\n",
            "time for get_cross_val_score : 31.59181022644043\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 924.9474391937256 \n",
            "\n",
            "slice 104 started......\n",
            "time for get_uncorr_data : 0.21852827072143555\n",
            "time for get_cross_val_score : 28.074284076690674\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 953.3508021831512 \n",
            "\n",
            "slice 105 started......\n",
            "time for get_uncorr_data : 0.2198798656463623\n",
            "time for get_cross_val_score : 28.453223705291748\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 982.1222140789032 \n",
            "\n",
            "slice 106 started......\n",
            "time for get_uncorr_data : 0.21880340576171875\n",
            "time for get_cross_val_score : 28.50601887702942\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 1010.9606454372406 \n",
            "\n",
            "slice 107 started......\n",
            "time for get_uncorr_data : 0.21050262451171875\n",
            "time for get_cross_val_score : 29.0832097530365\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 1040.3775026798248 \n",
            "\n",
            "slice 108 started......\n",
            "time for get_uncorr_data : 0.22113656997680664\n",
            "time for get_cross_val_score : 24.389053344726562\n",
            "columns selected to drop : 35 and   22 are droped\n",
            "total time required : 1065.0993542671204 \n",
            "\n",
            "slice 109 started......\n",
            "time for get_uncorr_data : 0.23809385299682617\n",
            "time for get_cross_val_score : 23.035686016082764\n",
            "columns selected to drop : 34 and   22 are droped\n",
            "total time required : 1088.4678361415863 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEoQNON5ugnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ceea0b8-9d6f-404f-bdb9-8cc7d02c8f29"
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((65, 110, 88, 110), (15, 110, 88, 110))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ZMZd34osM9"
      },
      "source": [
        "del y_train_0, y_test_0, y_0, y_train_1, y_test_1, y_1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4k8WBt5u9RN"
      },
      "source": [
        "del all_slices_knn_score, all_slices_rf_score, all_algo, all_knn_neighbours, new_correlated_block"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xewKv4jop0ze"
      },
      "source": [
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('all_droped_col', all_droped_col)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd8LLCBMCo-z"
      },
      "source": [
        "y_train = np.load('/content/y_train.npy')\n",
        "y_test = np.load('/content/y_test.npy')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um7BD2xQuJR8"
      },
      "source": [
        "new_y = np.empty((65*110,110,88))\n",
        "s1 = 0\n",
        "s2 = 110\n",
        "for i in range(65):\n",
        "    for j in range(110):\n",
        "        new_y[s1+j,:,:] = y_train[i,:,:,j]\n",
        "    s1 = s1+110\n",
        "\n",
        "new_y = new_y.reshape(65*110,110,88,1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrrlHu7UvYaY"
      },
      "source": [
        "training_data_gen = ImageDataGenerator(#target_size = (110,110),\n",
        "                                       rotation_range = 4, \n",
        "                                       width_shift_range = 0.0,\n",
        "                                       height_shift_range = 0.0,\n",
        "                                       shear_range = 0.1,\n",
        "                                       zoom_range = 0.02, \n",
        "                                       #mode = 'binary',\n",
        "                                       horizontal_flip = False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clI9wRxsva-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5816038e-d8a5-44da-8829-a8c40c4ed2a8"
      },
      "source": [
        "img_aug = training_data_gen.flow(x= new_y,  batch_size=65*110, shuffle=False)\n",
        "x_train_in, y_train_in = get_augmented_data(len(x_train_0), img_aug)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC87RcRGDZk_"
      },
      "source": [
        "np.save('x_train_in.npy', x_train_in)\n",
        "np.save('y_train_in.npy', y_train_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTzGRRVavhc7"
      },
      "source": [
        "fig, axe = plt.subplots(5,13, sharex=True, sharey=True, figsize = (25,7))\n",
        "\n",
        "for i in range(5):\n",
        "    for j in range(13):\n",
        "        s = (i*13 + j)*10\n",
        "        axe[i,j].imshow(x_train_in[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlS1OvxHv6dp"
      },
      "source": [
        "fig, axe = plt.subplots(5,13, sharex=True, sharey=True, figsize = (25,7))\n",
        "\n",
        "for i in range(5):\n",
        "    for j in range(13):\n",
        "        s = (i*13 + j)*10\n",
        "        axe[i,j].imshow(y_train_in[s][:,:,55])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj3Db6VeXs1U"
      },
      "source": [
        "# now we are certain that data afer augmentation is OK as all the images ploted here seems to be good and look like the available ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQz8mFQgrPsH"
      },
      "source": [
        "all_droped_col = np.load('all_droped_col.npy')\n",
        "len(all_droped_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm0tHiXArG9v"
      },
      "source": [
        "x_test = np.empty((15,110,88))\n",
        "for s,i in enumerate(x_test_0):\n",
        "  x_test[s] = cv2.resize(i, (88,110), interpolation = cv2.INTER_AREA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6xc7P2JuJXZ"
      },
      "source": [
        "plt.imshow(x_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ol7V7T-v89x"
      },
      "source": [
        "vgg_16 = VGG16(input_shape=(110,110,3), weights='imagenet', include_top=False)\n",
        "for layer in vgg_16.layers[:10]:\n",
        "    layer.trainable = False\n",
        "input = vgg_16.layers[:5]\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=1, kernel_size=(1,1), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape = (110,88,1)))    #LeakyReLU(alpha=1)\n",
        "model.add(keras.layers.experimental.preprocessing.RandomRotation(0.001))\n",
        "model.add(Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(input[0])\n",
        "model.add(input[1])\n",
        "model.add(input[2])\n",
        "#model.add(Conv2D(filters=3, kernel_size=(3,3), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "#model.add(Conv2D(filters=3, kernel_size=(3,3), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=8, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=110, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=110, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4wa_WNppOVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5fc1b9-bf72-4984-bbee-ff76fdc660c3"
      },
      "source": [
        "x_train_in.shape, y_train_in.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((650, 110, 88), (650, 110, 88, 110), (15, 110, 88), (15, 110, 88, 110))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PXyvFpiwInA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a9362e-126e-433e-c368-9faa1bfc75aa"
      },
      "source": [
        "#training_data_gen.fit(x)        # Adam(learning_rate=0.0008)\n",
        "model.compile(loss = 'mape', optimizer= Adam(learning_rate= 0.0001, beta_1 = 0.9, beta_2=0.999, amsgrad=True), metrics = ['mse'])\n",
        "# model.compile(loss = 'categorical_crossentropy', optimizer= SGD(learning_rate= 0.0001), metrics = ['accuracy', 'mean_squared_error'])\n",
        "history = model.fit(x_train_in.reshape(650, 110, 88, 1), y_train_in, batch_size=16, validation_data=(x_test.reshape(15, 110, 88,1), y_test), epochs = 50)\n",
        "\n",
        "# history = model.fit(x_train_in.reshape(650,110,88,1), y_train_in[:,:,:,:16], batch_size=33, validation_data=(x_test_0[:,:,:88].reshape(15,110,88,1), y_test[:,:,:,:16]), epochs = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "41/41 [==============================] - 89s 2s/step - loss: 365316053089.5238 - mse: 3762086.0714 - val_loss: 2010.6157 - val_mse: 2288583.0000\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 171190481871.2381 - mse: 1486060.4524 - val_loss: 1168.7255 - val_mse: 1293262.0000\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 93469732278.8571 - mse: 762441.3423 - val_loss: 697.3199 - val_mse: 898026.1250\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 45979344115.8095 - mse: 471707.9010 - val_loss: 424.6106 - val_mse: 712779.3125\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 17658927542.8571 - mse: 359098.2738 - val_loss: 193.2382 - val_mse: 642609.5625\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 6199427730.2857 - mse: 327213.9085 - val_loss: 119.3514 - val_mse: 619671.8750\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 2031112780.1905 - mse: 280966.6935 - val_loss: 107.2015 - val_mse: 614729.3750\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 823279058.2857 - mse: 301902.9174 - val_loss: 103.5621 - val_mse: 613218.3125\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 67s 2s/step - loss: 471724867.8095 - mse: 297002.4174 - val_loss: 102.0335 - val_mse: 612508.0625\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 67s 2s/step - loss: 265435737.5238 - mse: 310404.5491 - val_loss: 101.2632 - val_mse: 612120.8750\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 173837188.5714 - mse: 293110.0316 - val_loss: 100.7887 - val_mse: 611892.1250\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 111827307.2381 - mse: 305301.0379 - val_loss: 100.4989 - val_mse: 611762.0000\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 74637072.7619 - mse: 303674.5781 - val_loss: 100.3238 - val_mse: 611681.6875\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 51768794.4762 - mse: 288290.7325 - val_loss: 100.1989 - val_mse: 611631.4375\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 68s 2s/step - loss: 35452439.3810 - mse: 296703.3445 - val_loss: 100.1331 - val_mse: 611601.5000\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 23551503.3810 - mse: 309833.9926 - val_loss: 100.0921 - val_mse: 611582.0625\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 16343895.8571 - mse: 315883.2039 - val_loss: 100.0610 - val_mse: 611569.1250\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 71s 2s/step - loss: 12339055.5238 - mse: 311963.7909 - val_loss: 100.0387 - val_mse: 611560.3125\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 9261957.7381 - mse: 305726.4524 - val_loss: 100.0260 - val_mse: 611554.6250\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 7152068.8810 - mse: 295218.3438 - val_loss: 100.0188 - val_mse: 611550.7500\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 71s 2s/step - loss: 5473170.4167 - mse: 304429.2972 - val_loss: 100.0137 - val_mse: 611548.0625\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 4594850.2679 - mse: 283434.5182 - val_loss: 100.0105 - val_mse: 611546.0625\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 3399898.2083 - mse: 303896.4368 - val_loss: 100.0085 - val_mse: 611544.6250\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 2601758.0595 - mse: 329043.7932 - val_loss: 100.0067 - val_mse: 611543.5000\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 69s 2s/step - loss: 2264780.6637 - mse: 307022.4278 - val_loss: 100.0054 - val_mse: 611542.6250\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 2030631.0298 - mse: 288524.2991 - val_loss: 100.0043 - val_mse: 611541.9375\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 1789671.3006 - mse: 283819.8062 - val_loss: 100.0036 - val_mse: 611541.3125\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 71s 2s/step - loss: 1374832.8780 - mse: 306172.5097 - val_loss: 100.0030 - val_mse: 611540.8125\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 1188248.7024 - mse: 322730.7292 - val_loss: 100.0025 - val_mse: 611540.5000\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 1073961.5432 - mse: 289409.9818 - val_loss: 100.0021 - val_mse: 611540.1250\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 927989.7083 - mse: 304293.1696 - val_loss: 100.0018 - val_mse: 611539.9375\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 820301.9732 - mse: 302757.5253 - val_loss: 100.0016 - val_mse: 611539.6250\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 691904.8914 - mse: 311876.4200 - val_loss: 100.0014 - val_mse: 611539.4375\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 70s 2s/step - loss: 633527.7857 - mse: 306880.4844 - val_loss: 100.0012 - val_mse: 611539.3750\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 71s 2s/step - loss: 529343.9881 - mse: 329313.2262 - val_loss: 100.0011 - val_mse: 611539.1875\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 71s 2s/step - loss: 521270.8817 - mse: 310011.4308 - val_loss: 100.0010 - val_mse: 611539.0000\n",
            "Epoch 37/50\n",
            "21/41 [==============>...............] - ETA: 34s - loss: 536692.2574 - mse: 279141.8653"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT2FDy3Ei-G0"
      },
      "source": [
        "plot_loss_curve(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYeau4lImDeV"
      },
      "source": [
        "# history = model.fit(x_train_in.reshape(650, 110, 88, 1), y_train_in, batch_size=16, validation_data=(x_test.reshape(15, 110, 88,1), y_test), epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2PNa29hmKj"
      },
      "source": [
        "new = model.predict(x_test_0[:1,:,:88].reshape(1,110,88,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKMFe758h3iv"
      },
      "source": [
        "plt.imshow(new[0,:,:,15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGqGmS0qTUJD"
      },
      "source": [
        "Here i am taking the kerner_size = (1,1) because it become easy to optimize small filters then larger one like (3,3) or (5,5) with less data as in our case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Ofb_q4TzYa"
      },
      "source": [
        "Further while reversing the process of code execution, it becomes easier with small kernel size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPU8idnTv_Tt"
      },
      "source": [
        "# In this approach of model building, model have to predict 110 pixels corresponding to 1 pixel. So the process seems to be very complex.\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=110, kernel_size=(1,1), padding='same', kernel_initializer='he_uniform', activation='linear', input_shape = (110,88,110)))    \n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=8, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=8, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "# model.add(input[0])\n",
        "# model.add(input[1])\n",
        "# model.add(input[2])\n",
        "model.add(Conv2D(filters=1, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=1, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(110, activation='linear'))\n",
        "# model.add(Dense(110, activation='linear'))\n",
        "# model.add(Dense(110, activation='linear'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWg2DQTgwgQZ"
      },
      "source": [
        "model.compile(loss = 'mape', optimizer= Adam(learning_rate= 0.001), metrics = ['mse'])     \n",
        "history = model.fit(y_train_in, x_train_in, batch_size=16, validation_data=(y_test.reshape(15,110,88,110), x_test.reshape(15,110,88,1)), epochs = 10)      # .reshape(650,110)   # .reshape(15,110)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXklg-YgTkk4"
      },
      "source": [
        "history = model.fit(y_train_in, x_train_in, batch_size=16, validation_data=(y_test.reshape(15,110,88,110), x_test.reshape(15,110,88,1)), epochs = 50)      # .reshape(650,110)   # .reshape(15,110)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvS-3J7RZRD"
      },
      "source": [
        "x_train_in[:,:,0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIiWfi4bwgUe"
      },
      "source": [
        "history = model.fit(y_train_in, x_train_in.reshape(650,110,88,110), batch_size=16, validation_data=(y_test[:,:,:,0], x_test_0[:,:,:1].reshape(15,110,1)), epochs = 50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzJ6E9lUfRZ"
      },
      "source": [
        "Now i am building a model which wolud be trained to predict X-Ray images with a hope that it is easier to train the model for making prediction on (110,110,110) to (110,110) shape. As now it will predict 1 pixel corresponding to 110 pixels which makes the training less complex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amFzmLg42rpp"
      },
      "source": [
        "# vgg_16 = VGG16(input_shape=(110,110,3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg_16.layers[:10]:\n",
        "#     layer.trainable = False\n",
        "# input = vgg_16.layers[:5]\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=110, kernel_size=(1,1), padding='same', kernel_initializer='he_uniform', activation='relu', input_shape = (110,88,110)))    \n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "# model.add(Conv2D(filters=32, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "# model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=8, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=8, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "# model.add(Conv2D(filters=5, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='linear'))\n",
        "model.add(Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=3, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "\n",
        "# model.add(input[0])\n",
        "# model.add(input[1])\n",
        "# model.add(input[2])\n",
        "model.add(Conv2D(filters=1, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Conv2D(filters=1, kernel_size=(1,1), padding=\"same\", kernel_initializer='he_uniform', activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9b3XhNU3UaV"
      },
      "source": [
        "model.compile(loss = 'mean_squared_error', optimizer= Adam(learning_rate= 0.01), metrics = ['mse'])\n",
        "history = model.fit(y_train_in, x_train_in, batch_size=16, validation_data=(y_test, x_test.reshape(15,110,88,1)), epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7rLKhEhRXht"
      },
      "source": [
        "As we build a model to predict X-Ray images from 3D array of CT scane images. But we have to do the reverse. Lets do the reverse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWV6cT9Vg6Tw"
      },
      "source": [
        "plt.figure(figsize = (20,8))\n",
        "temp = plt.imread('/content/drive/MyDrive/2D_to_3D.png')\n",
        "plt.imshow(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gGcmzLQ25s"
      },
      "source": [
        "model_weights = model.weights   # take the weights from the trained model\n",
        "\n",
        "# the weights taken directly have contain some unwanted string formated material\n",
        "# Lets append just weights and biases to list\n",
        "lst = list()\n",
        "for i in model_weights:\n",
        "    lst.append(np.array(i)) \n",
        "    \n",
        "np.save('/content/model_weights.npy', lst)    # saving temperaly in cloud storage.\n",
        "lst = np.load('/content/model_weights.npy', allow_pickle=True)\n",
        "\n",
        "# now lets seperate the weights and biases and appending them in seperate list\n",
        "weights = list()\n",
        "bias = list()\n",
        "for i in range(0,len(lst),2):\n",
        "    weights.append(lst[i])\n",
        "    bias.append(lst[i+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX92GOddQu3T"
      },
      "source": [
        "# The formulization involved in the  the process is as follpw\n",
        "# z = w.x + b\n",
        "\n",
        "# so we need to find new metrics formed at every step. After that we will be able to calculate weights in reverse process\n",
        "\n",
        "A = y_test[0]\n",
        "list_A = list()\n",
        "for i in np.arange(0,len(lst), 2):\n",
        "    w = lst[i]\n",
        "    b = lst[i+1]\n",
        "    temp_shape = [110,88]\n",
        "    temp_shape.append(w.shape[3])\n",
        "    temp_A = np.empty(tuple(temp_shape))\n",
        "    for j in range(w.shape[3]):\n",
        "        # C_shape = [110,88]\n",
        "        # C_shape.append(w.shape[2])\n",
        "        C = np.empty((110,88))\n",
        "        for k in range(w.shape[2]):\n",
        "            C += np.multiply(A[:,:,k].reshape(110,88), w[:,:,k,j].reshape(1,1)).reshape(110,88)\n",
        "        temp_A[:,:,j] = C + b[j]\n",
        "        temp_A[temp_A<0] = 0\n",
        "    list_A.append(temp_A)\n",
        "    A = temp_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUHtZtUZQvFn"
      },
      "source": [
        "# calculate the weights, bias for reverse process\n",
        "\n",
        "new_weights = list() \n",
        "new_bias = bias[::-1]   \n",
        "new_list_A = list_A[::-1]\n",
        "for i in range(len(new_list_A)-1):\n",
        "    A = new_list_A[i][:new_list_A[i].shape[2],0,:] - new_bias[i]\n",
        "    A_1_shape = list(new_list_A[i+1].shape)\n",
        "    temp_shape = [1,1]\n",
        "    temp_shape.append(new_list_A[i].shape[2])\n",
        "    temp_shape.append(A_1_shape[2])\n",
        "    print(temp_shape)\n",
        "    #temp_shape = (list(new_list_A[i].shape)[2], list(A_1_shape)[2])\n",
        "    temp_w = np.empty(tuple(temp_shape))\n",
        "    for j in range(A_1_shape[2]):\n",
        "        B = (new_list_A[i+1][:new_list_A[i].shape[-1],0,j] - new_bias[i+1][j])    # .reshape(110,1)\n",
        "        # B = new_list_A[i+1][:,0,j].reshape(110,1)\n",
        "        print(A.shape, B.shape)\n",
        "        C = np.linalg.solve(A,B).reshape(1,1,new_list_A[i].shape[2])\n",
        "        print(C.shape)\n",
        "        temp_w[:,:,:,j] = C\n",
        "    new_weights.append(temp_w)\n",
        "    print(temp_w.shape, new_bias[i+1].shape)\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LwpeNbIQvIT"
      },
      "source": [
        "# make the prediction\n",
        "A = x[0][:,:88,:1]\n",
        "for i in range(len(new_weights)):\n",
        "    temp_shape = [110,88]\n",
        "    temp_shape.append(new_weights[i].shape[-1])\n",
        "    A_new = np.empty(tuple(temp_shape))\n",
        "    for j in range(A_new.shape[-1]):\n",
        "        temp_A = np.empty((110,88,1))\n",
        "        for k in range(A.shape[-1]):\n",
        "            print(A[:,:,k].shape, new_weights[i][0,0,:,k].shape)\n",
        "            temp_A += np.multiply(A[:,:,k], new_weights[i][1,1,:,k])\n",
        "            print(temp_A.shape)\n",
        "    A_new[:,:,j] = temp_A - new_bias[i]\n",
        "    A = A_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6HobUKAS0oL"
      },
      "source": [
        "new = model.predict(x_train_in[0:1,].reshape(1,110,88,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qLODSgshZIh"
      },
      "source": [
        "plt.imshow(x_test[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvbab52YTFAa"
      },
      "source": [
        "plt.imshow(new[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sct0ZOt2k7kj"
      },
      "source": [
        "These further steps are for reloading od saved data as the the notebook gets crashed due to limited hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3iVZWYI9U3P"
      },
      "source": [
        "x_0 = np.load('/content/Data_in_0.npy')\n",
        "# y_0 = np.load('/content/Data_out_0.npy')\n",
        "\n",
        "# x_train_0 = x_0[:65]\n",
        "x_test_0 = x_0[65:]\n",
        "# y_train_0 = y_0[:65]\n",
        "# y_test_0 = y_0[65:]\n",
        "# del x_0, y_train_0, y_test_0, y_0\n",
        "\n",
        "# y_train = np.load('/content/y_train.npy')\n",
        "y_test = np.load('/content/y_test.npy')\n",
        "\n",
        "y_train_in = np.load('/content/y_train_in.npy')\n",
        "x_train_in = np.load('/content/x_train_in.npy')\n",
        "\n",
        "x_test = np.empty((15,110,88))\n",
        "for s,i in enumerate(x_test_0):\n",
        "  x_test[s] = cv2.resize(i, (88,110), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "# def r_squared(x,y):\n",
        "#   x = np.array(x)\n",
        "#   y = np.array(y)\n",
        "#   slope, intercept, r_value, p_value, std_error = scipy.stats.linregress(x,y)\n",
        "#   r_value = tf.TensorArray(r_value)\n",
        "#   return r_value**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2QSpumFTkLR"
      },
      "source": [
        "y_0 = np.load('/content/Data_out_0.npy')\n",
        "x_train_0 = x_0[:65]\n",
        "x_test_0 = x_0[65:]\n",
        "y_train_0 = y_0[:65]\n",
        "y_test_0 = y_0[65:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpThZSKH_aN5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}